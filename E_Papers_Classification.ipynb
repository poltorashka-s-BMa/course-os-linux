{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poltorashka-s-BMa/course-os-linux/blob/main/E_Papers_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f13b3f4-01f6-4bd6-9262-fd01be3f463c",
      "metadata": {
        "id": "6f13b3f4-01f6-4bd6-9262-fd01be3f463c"
      },
      "source": [
        "# Задача F: Классификация научных статей по цитированиям\n",
        "Добро пожаловать на соревнование!\n",
        "\n",
        "В этом ноутбуке мы разберем задачу классификации научных статей, подготовим данные, создадим простой бейзлайн и основной шаблон для построения графовой нейронной сети, а также сформируем файл с решением для отправки в систему."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e664d887-0877-449d-943f-dfcbc0301d5b",
      "metadata": {
        "id": "e664d887-0877-449d-943f-dfcbc0301d5b"
      },
      "source": [
        "### Легенда задачи\n",
        "\n",
        "Вы работаете в научном издательстве, которое управляет огромной базой данных статей. Каждая статья относится к одной из 20 научных областей (например, \"биоинформатика\", \"машинное обучение\", \"квантовая физика\"). Ваша задача — восстановить утерянные метки областей для 440 статей, используя текстовые эмбеддинги и граф цитирований."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16f5dbbc-9cf5-4c3c-b065-d595b20127e0",
      "metadata": {
        "id": "16f5dbbc-9cf5-4c3c-b065-d595b20127e0"
      },
      "source": [
        "## Шаг 1: Загрузка и подготовка данных\n",
        "Сначала импортируем все необходимые библиотеки и загрузим наши данные. Для этого соревнования мы сгенерируем данные прямо в ноутбуке, чтобы он был полностью самодостаточным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b16887e5-bded-4926-bfdd-671b36fbf97e",
      "metadata": {
        "id": "b16887e5-bded-4926-bfdd-671b36fbf97e"
      },
      "outputs": [],
      "source": [
        "# Эти библиотеки вам наверняка пригодятся\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Эти будут полезны для создания моделей\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "\n",
        "# А эти могут понядобиться для расчета и визуализации результата\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b110d4d8-5655-48d2-9acd-6bd4cdb05241",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b110d4d8-5655-48d2-9acd-6bd4cdb05241",
        "outputId": "d7613786-ada4-4cb8-d71a-04a3dd3c2ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример элемента из embeddings_data (только ключи):\n",
            "dict_keys(['id', 'label', 'embedding', 'split'])\n",
            "\n",
            "Пример ребра из graph_data:\n",
            "[0, 280]\n",
            "\n",
            "Всего вершин: 1440\n",
            "Из них в обучении (train): 1000\n",
            "Из них в тесте (test): 440\n",
            "Всего ребер в графе: 11471\n"
          ]
        }
      ],
      "source": [
        "# Загрузка данных\n",
        "with open('embeddings_data.json', 'r') as f:\n",
        "    embeddings_data = json.load(f)\n",
        "with open('graph_data.json', 'r') as f:\n",
        "    graph_data = json.load(f)\n",
        "\n",
        "# Посмотрим на структуру\n",
        "print(\"Пример элемента из embeddings_data (только ключи):\")\n",
        "print(embeddings_data[0].keys())\n",
        "print(\"\\nПример ребра из graph_data:\")\n",
        "print(graph_data[0])\n",
        "\n",
        "# Разделим данные на обучающую и тестовую выборки\n",
        "train_data = [d for d in embeddings_data if d['split'] == 'train']\n",
        "test_data = [d for d in embeddings_data if d['split'] == 'test']\n",
        "\n",
        "print(f\"\\nВсего вершин: {len(embeddings_data)}\")\n",
        "print(f\"Из них в обучении (train): {len(train_data)}\")\n",
        "print(f\"Из них в тесте (test): {len(test_data)}\")\n",
        "print(f\"Всего ребер в графе: {len(graph_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dc3c128-e0a9-4783-8d06-adf77a37f844",
      "metadata": {
        "id": "2dc3c128-e0a9-4783-8d06-adf77a37f844"
      },
      "source": [
        "## Шаг 2: Бейзлайн на основе структуры графа\n",
        "Давайте построим простое базовое решение (бейзлайн), которое использует только структуру графа и полностью игнорирует эмбеддинги. Логика простая: для каждой тестовой вершины предскажем тот класс, который чаще всего встречается среди её соседей из обучающей выборки.\n",
        "\n",
        "Ваша задача — заполнить пропущенные части в коде ниже."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_baseline_predictor(graph_data, embeddings_data, num_classes=20):\n",
        "    \"\"\"\n",
        "    Предсказывает классы для тестовых вершин на основе самого популярного класса\n",
        "    среди соседей из обучающей выборки.\n",
        "    \"\"\"\n",
        "    adj_list = defaultdict(list)\n",
        "    for u, v in graph_data:\n",
        "        adj_list[u].append(v)\n",
        "        adj_list[v].append(u)  # Делаем граф двунаправленным\n",
        "\n",
        "    node_info = {d['id']: d for d in embeddings_data}\n",
        "    test_node_ids = [d['id'] for d in embeddings_data if d.get('split') == 'test']\n",
        "\n",
        "    predictions = {}\n",
        "\n",
        "    for node_id in test_node_ids:\n",
        "        all_neighbors = adj_list.get(node_id, [])\n",
        "        train_neighbors = [n for n in all_neighbors if n in node_info and node_info[n]['split'] == 'train']\n",
        "\n",
        "        if not train_neighbors:\n",
        "            predictions[node_id] = random.randint(0, num_classes - 1)\n",
        "            continue\n",
        "\n",
        "        neighbor_labels = [node_info[n_id]['label'] for n_id in train_neighbors]\n",
        "\n",
        "        if not neighbor_labels:\n",
        "            predictions[node_id] = random.randint(0, num_classes - 1)\n",
        "            continue\n",
        "\n",
        "        label_counts = Counter(neighbor_labels)\n",
        "        predicted_class = label_counts.most_common(1)[0][0]\n",
        "        predictions[node_id] = predicted_class\n",
        "\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "3PgNgJOw1Xp1"
      },
      "id": "3PgNgJOw1Xp1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_predictions = graph_baseline_predictor(graph_data, embeddings_data)"
      ],
      "metadata": {
        "id": "t2OYUeIW5SRq"
      },
      "id": "t2OYUeIW5SRq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f4718b91-4ad3-4a4f-85cf-11c61fcbe36d",
      "metadata": {
        "id": "f4718b91-4ad3-4a4f-85cf-11c61fcbe36d"
      },
      "source": [
        "**Подсказка:** Если вы все сделаете правильно, точность этого бейзлайна должна быть в районе 0.4. По формуле оценки это даст вам около 2 баллов. Ваша цель — значительно превзойти этот результат!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "519111a6-43f7-4eff-b0b1-5698cfcd120b",
      "metadata": {
        "id": "519111a6-43f7-4eff-b0b1-5698cfcd120b"
      },
      "source": [
        "### Шаг 3: Функция для сохранения решения\n",
        "Определим функцию для выгрузки решения сразу. Она понадобится нам и для бейзлайна, и для финальной модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "707fcc33-5aeb-4883-8ca9-9438ca4d2459",
      "metadata": {
        "id": "707fcc33-5aeb-4883-8ca9-9438ca4d2459"
      },
      "outputs": [],
      "source": [
        "def save_predictions_to_csv(predictions_dict, filename=\"predictions.csv\"):\n",
        "    \"\"\"\n",
        "    Сохраняет предсказания из словаря в CSV файл для отправки в систему.\n",
        "    \"\"\"\n",
        "    # Убедимся, что predictions_dict содержит предсказания для всех тестовых вершин\n",
        "    test_ids = {d['id'] for d in embeddings_data if d['split'] == 'test'}\n",
        "    if set(predictions_dict.keys()) != test_ids:\n",
        "        print(\"Внимание! В словаре предсказаний отсутствуют некоторые тестовые ID.\")\n",
        "\n",
        "    pred_df = pd.DataFrame(list(predictions_dict.items()), columns=['id', 'label'])\n",
        "    pred_df = pred_df.sort_values(by='id')\n",
        "    pred_df.to_csv(filename, header=False, index=False)\n",
        "\n",
        "    print(f\"\\nРешение успешно сохранено в файл: {filename}\")\n",
        "    print(\"Пример содержимого файла:\")\n",
        "    # Магическая команда для вывода первых строк файла в Jupyter\n",
        "    !head -n 5 {filename}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3185d045-5cba-4a26-ba5d-e7c50684db32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3185d045-5cba-4a26-ba5d-e7c50684db32",
        "outputId": "fcea2eb3-9f45-46df-9a70-877e50c9591c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Решение успешно сохранено в файл: baseline_predictions.csv\n",
            "Пример содержимого файла:\n",
            "1000,18\n",
            "1001,4\n",
            "1002,3\n",
            "1003,8\n",
            "1004,10\n"
          ]
        }
      ],
      "source": [
        "save_predictions_to_csv(baseline_predictions, \"baseline_predictions.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7925ed08-4922-4d46-88ae-e4a62626de54",
      "metadata": {
        "id": "7925ed08-4922-4d46-88ae-e4a62626de54"
      },
      "source": [
        "## Шаг 4: Построение финальной модели (GNN)\n",
        "Теперь ваша очередь построить графовую нейросеть! Вам предстоит пройти все этапы: подготовка данных, определение архитектуры, обучение и получение предсказаний."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "841f6395-967a-40be-8707-31968c86a3ae",
      "metadata": {
        "id": "841f6395-967a-40be-8707-31968c86a3ae"
      },
      "source": [
        "### 4.1: Подготовка данных и создание выборок\n",
        "Сначала подготовим данные в формате PyTorch Geometric. Самое важное — мы разделим обучающую выборку (train) на две части: новую, уменьшенную обучающую (new_train) и валидационную (val).\n",
        "\n",
        "Валидационная выборка критически важна для:\n",
        "\n",
        "- Настройки гиперпараметров (скорость обучения, глубина сети и т.д.).\n",
        "- Отслеживания переобучения и применения Early Stopping."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Gmt6F5nK7rdg"
      },
      "id": "Gmt6F5nK7rdg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b238fb40-2eec-4076-a38c-10c97cfd1250",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b238fb40-2eec-4076-a38c-10c97cfd1250",
        "outputId": "b2654a4e-0d09-471a-a8b3-54b10b3b30ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Объект данных PyTorch Geometric:\n",
            "Data(x=[1440, 1024], edge_index=[2, 11471], y=[1440], train_mask=[1440], val_mask=[1440], test_mask=[1440])\n",
            "Новый размер train: 800\n",
            "Размер validation: 200\n",
            "Размер test: 440\n"
          ]
        }
      ],
      "source": [
        "# --- Создание тензоров ---\n",
        "all_labels = {d['id']: d.get('label', -1) for d in embeddings_data}\n",
        "x = torch.tensor([d['embedding'] for d in embeddings_data], dtype=torch.float)\n",
        "y = torch.tensor([all_labels[i] for i in range(len(embeddings_data))], dtype=torch.long)\n",
        "edge_index = torch.tensor(graph_data, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# --- Создание масок ---\n",
        "# Сначала найдем ID всех обучающих вершин\n",
        "train_ids = [d['id'] for d in embeddings_data if d['split'] == 'train']\n",
        "\n",
        "\n",
        "train_ids_new, val_ids = train_test_split(\n",
        "    train_ids,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=[all_labels[i] for i in train_ids]\n",
        ")\n",
        "\n",
        "# Теперь создаем маски PyTorch на основе этих ID\n",
        "train_mask = torch.zeros(len(embeddings_data), dtype=torch.bool)\n",
        "val_mask = torch.zeros(len(embeddings_data), dtype=torch.bool)\n",
        "test_mask = torch.zeros(len(embeddings_data), dtype=torch.bool)\n",
        "\n",
        "train_mask[train_ids_new] = True\n",
        "val_mask[val_ids] = True\n",
        "test_mask[[d['id'] for d in embeddings_data if d['split'] == 'test']] = True\n",
        "\n",
        "# Собираем все в один объект Data\n",
        "pyg_data = Data(x=x, edge_index=edge_index, y=y,\n",
        "                train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n",
        "\n",
        "print(\"Объект данных PyTorch Geometric:\")\n",
        "print(pyg_data)\n",
        "print(f\"Новый размер train: {pyg_data.train_mask.sum().item()}\")\n",
        "print(f\"Размер validation: {pyg_data.val_mask.sum().item()}\")\n",
        "print(f\"Размер test: {pyg_data.test_mask.sum().item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2882017-4a4d-402f-b254-f93b965210fc",
      "metadata": {
        "id": "c2882017-4a4d-402f-b254-f93b965210fc"
      },
      "source": [
        "### 4.2: Определение архитектуры модели\n",
        "Ваша задача — спроектировать и написать класс для GNN модели.\n",
        "\n",
        "Примерный план архитектуры:\n",
        "\n",
        "1. Вход: Принимает объект pyg_data.\n",
        "2. Слой 1: Графовый сверточный слой (например, GCNConv или GATConv), который преобразует входные эмбеддинги в промежуточное представление. После него — функция активации (например, ReLU).\n",
        "3. Регуляризация: Слой Dropout для борьбы с переобучением.\n",
        "4. Слой 2: Еще один графовый сверточный слой.\n",
        "5. Классификатор (MLP): После графовых слоев можно добавить небольшой полносвязный слой (nn.Linear) для финальной классификации.\n",
        "6. Выход: Логиты для каждого из 20 классов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_p=0.6):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "        self.dropout1 = nn.Dropout(p=dropout_p)\n",
        "\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "        self.dropout2 = nn.Dropout(p=dropout_p)\n",
        "\n",
        "        self.classifier_lin = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.classifier_lin(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4zuDal3GHQsH"
      },
      "id": "4zuDal3GHQsH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ee4b1140-e4fb-4738-a963-6bc7e79e2037",
      "metadata": {
        "id": "ee4b1140-e4fb-4738-a963-6bc7e79e2037"
      },
      "source": [
        "### 4.3: Обучение модели\n",
        "Напишите цикл обучения. Следите за loss и accuracy на обучающей и валидационной выборках."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, BatchNorm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "in_channels = pyg_data.x.size(1)\n",
        "hidden_channels = 128\n",
        "out_channels = 20\n",
        "\n",
        "model = MyGNN(in_channels, hidden_channels, out_channels, dropout_p=0.6).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "scheduler = StepLR(optimizer, step_size=100, gamma=0.5)  # снижать lr каждые 100 эпох в 2 раза\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "pyg_data = pyg_data.to(device)\n",
        "\n",
        "best_val_acc = 0\n",
        "best_model_state = None\n",
        "patience = 30\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(1, 501):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    out = model(pyg_data)\n",
        "    loss = criterion(out[pyg_data.train_mask], pyg_data.y[pyg_data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(pyg_data)\n",
        "        pred = out.argmax(dim=1)\n",
        "\n",
        "        train_acc = (pred[pyg_data.train_mask] == pyg_data.y[pyg_data.train_mask]).float().mean().item()\n",
        "        val_acc = (pred[pyg_data.val_mask] == pyg_data.y[pyg_data.val_mask]).float().mean().item()\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == 1:\n",
        "        print(f\"Эпоха: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(f\"Ранняя остановка на эпохе {epoch}. Лучшая Val Acc: {best_val_acc:.4f}\")\n",
        "        break\n",
        "\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "if pyg_data.test_mask.sum() > 0 and (pyg_data.y[pyg_data.test_mask] >= 0).all():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(pyg_data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        test_acc = (pred[pyg_data.test_mask] == pyg_data.y[pyg_data.test_mask]).float().mean().item()\n",
        "    print(f\"Точность на тесте: {test_acc:.4f}\")\n",
        "else:\n",
        "    print(\"Нет меток для теста или тестовый набор пуст\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKpTmpQsHVnl",
        "outputId": "32ed1a5e-9508-4b9a-a21f-38419390f0b7"
      },
      "id": "JKpTmpQsHVnl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха: 001, Loss: 3.0613, Train Acc: 0.0637, Val Acc: 0.0650\n",
            "Эпоха: 010, Loss: 1.7456, Train Acc: 0.1900, Val Acc: 0.1500\n",
            "Эпоха: 020, Loss: 1.1251, Train Acc: 0.1688, Val Acc: 0.1600\n",
            "Эпоха: 030, Loss: 0.8018, Train Acc: 0.2075, Val Acc: 0.1550\n",
            "Эпоха: 040, Loss: 0.6229, Train Acc: 0.7625, Val Acc: 0.3500\n",
            "Эпоха: 050, Loss: 0.4747, Train Acc: 0.7638, Val Acc: 0.3600\n",
            "Эпоха: 060, Loss: 0.4286, Train Acc: 0.8425, Val Acc: 0.3650\n",
            "Эпоха: 070, Loss: 0.3244, Train Acc: 0.9237, Val Acc: 0.3600\n",
            "Эпоха: 080, Loss: 0.3009, Train Acc: 0.9100, Val Acc: 0.3550\n",
            "Ранняя остановка на эпохе 83. Лучшая Val Acc: 0.4550\n",
            "Нет меток для теста или тестовый набор пуст\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7c7822-e625-43c4-9f19-b51f50edfe32",
      "metadata": {
        "id": "fc7c7822-e625-43c4-9f19-b51f50edfe32"
      },
      "source": [
        "## Шаг 5: Выгрузка решения\n",
        "После того, как вы обучили вашу лучшую модель и получили словарь final_predictions, его нужно сохранить в predictions.csv в правильном формате для отправки в систему."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ddb6bd4-4842-4e9b-b2fe-f02ee49dbe93",
      "metadata": {
        "id": "0ddb6bd4-4842-4e9b-b2fe-f02ee49dbe93"
      },
      "outputs": [],
      "source": [
        "# 1. Переключаем модель в eval режим\n",
        "model.eval()\n",
        "\n",
        "# 2. Предсказания для всех узлов\n",
        "with torch.no_grad():\n",
        "    out = model(pyg_data)\n",
        "    preds = out.argmax(dim=1).cpu().numpy()  # Получаем классы\n",
        "\n",
        "# 3. Выбираем только тестовые узлы\n",
        "test_indices = pyg_data.test_mask.nonzero(as_tuple=False).view(-1).cpu().numpy()\n",
        "\n",
        "# 4. Формируем словарь id: predicted_label для теста\n",
        "final_predictions = {}\n",
        "for idx in test_indices:\n",
        "    article_id = idx.item()  # id вершины в графе\n",
        "    predicted_label = int(preds[idx])\n",
        "    final_predictions[article_id] = predicted_label\n",
        "\n",
        "# Функция сохранения, если её нет, вот простая реализация:\n",
        "def save_predictions_to_csv(predictions_dict, filename=\"predictions.csv\"):\n",
        "    with open(filename, \"w\") as f:\n",
        "        for id_, label in sorted(predictions_dict.items()):\n",
        "            f.write(f\"{id_},{label}\\n\")\n",
        "\n",
        "# Сохраняем в файл\n",
        "save_predictions_to_csv(final_predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04824c82-424c-41f3-9784-0517751436a3",
      "metadata": {
        "id": "04824c82-424c-41f3-9784-0517751436a3"
      },
      "source": [
        "Готово! Теперь у вас есть файл predictions.csv, который можно загружать в систему. Попробуйте улучшить свой результат!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ef59665",
        "outputId": "c9d05ff7-97de-459f-e910-90693c115c61"
      },
      "source": [
        "!pip install torch_geometric"
      ],
      "id": "7ef59665",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}