{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poltorashka-s-BMa/course-os-linux/blob/main/E_Papers_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f13b3f4-01f6-4bd6-9262-fd01be3f463c",
      "metadata": {
        "id": "6f13b3f4-01f6-4bd6-9262-fd01be3f463c"
      },
      "source": [
        "# Задача F: Классификация научных статей по цитированиям\n",
        "Добро пожаловать на соревнование!\n",
        "\n",
        "В этом ноутбуке мы разберем задачу классификации научных статей, подготовим данные, создадим простой бейзлайн и основной шаблон для построения графовой нейронной сети, а также сформируем файл с решением для отправки в систему."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e664d887-0877-449d-943f-dfcbc0301d5b",
      "metadata": {
        "id": "e664d887-0877-449d-943f-dfcbc0301d5b"
      },
      "source": [
        "### Легенда задачи\n",
        "\n",
        "Вы работаете в научном издательстве, которое управляет огромной базой данных статей. Каждая статья относится к одной из 20 научных областей (например, \"биоинформатика\", \"машинное обучение\", \"квантовая физика\"). Ваша задача — восстановить утерянные метки областей для 440 статей, используя текстовые эмбеддинги и граф цитирований."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16f5dbbc-9cf5-4c3c-b065-d595b20127e0",
      "metadata": {
        "id": "16f5dbbc-9cf5-4c3c-b065-d595b20127e0"
      },
      "source": [
        "## Шаг 1: Загрузка и подготовка данных\n",
        "Сначала импортируем все необходимые библиотеки и загрузим наши данные. Для этого соревнования мы сгенерируем данные прямо в ноутбуке, чтобы он был полностью самодостаточным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b16887e5-bded-4926-bfdd-671b36fbf97e",
      "metadata": {
        "id": "b16887e5-bded-4926-bfdd-671b36fbf97e"
      },
      "outputs": [],
      "source": [
        "# Эти библиотеки вам наверняка пригодятся\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Эти будут полезны для создания моделей\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "\n",
        "# А эти могут понядобиться для расчета и визуализации результата\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b110d4d8-5655-48d2-9acd-6bd4cdb05241",
      "metadata": {
        "id": "b110d4d8-5655-48d2-9acd-6bd4cdb05241"
      },
      "outputs": [],
      "source": [
        "# Загрузка данных\n",
        "with open('embeddings_data.json', 'r') as f:\n",
        "    embeddings_data = json.load(f)\n",
        "with open('graph_data.json', 'r') as f:\n",
        "    graph_data = json.load(f)\n",
        "\n",
        "# Посмотрим на структуру\n",
        "print(\"Пример элемента из embeddings_data (только ключи):\")\n",
        "print(embeddings_data[0].keys())\n",
        "print(\"\\nПример ребра из graph_data:\")\n",
        "print(graph_data[0])\n",
        "\n",
        "# Разделим данные на обучающую и тестовую выборки\n",
        "train_data = [d for d in embeddings_data if d['split'] == 'train']\n",
        "test_data = [d for d in embeddings_data if d['split'] == 'test']\n",
        "\n",
        "print(f\"\\nВсего вершин: {len(embeddings_data)}\")\n",
        "print(f\"Из них в обучении (train): {len(train_data)}\")\n",
        "print(f\"Из них в тесте (test): {len(test_data)}\")\n",
        "print(f\"Всего ребер в графе: {len(graph_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dc3c128-e0a9-4783-8d06-adf77a37f844",
      "metadata": {
        "id": "2dc3c128-e0a9-4783-8d06-adf77a37f844"
      },
      "source": [
        "## Шаг 2: Бейзлайн на основе структуры графа\n",
        "Давайте построим простое базовое решение (бейзлайн), которое использует только структуру графа и полностью игнорирует эмбеддинги. Логика простая: для каждой тестовой вершины предскажем тот класс, который чаще всего встречается среди её соседей из обучающей выборки.\n",
        "\n",
        "Ваша задача — заполнить пропущенные части в коде ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a70f9f5-a6ce-4ffd-9c35-caeb109d83d0",
      "metadata": {
        "id": "4a70f9f5-a6ce-4ffd-9c35-caeb109d83d0"
      },
      "outputs": [],
      "source": [
        "def graph_baseline_predictor(graph_data, embeddings_data, num_classes=20):\n",
        "    \"\"\"\n",
        "    Предсказывает классы для тестовых вершин на основе самого популярного класса\n",
        "    среди соседей из обучающей выборки.\n",
        "    \"\"\"\n",
        "    adj_list = defaultdict(list)\n",
        "    for u, v in graph_data:\n",
        "        adj_list[u].append(v)\n",
        "\n",
        "    node_info = {d['id']: d for d in embeddings_data}\n",
        "    test_node_ids = [d['id'] for d in embeddings_data if d.get('split') == 'test']\n",
        "\n",
        "    predictions = {}\n",
        "\n",
        "    for node_id in test_node_ids:\n",
        "        all_neighbors = adj_list.get(node_id, [])\n",
        "        train_neighbors = ... # [!] ВАШ КОД: отфильтруйте соседей, оставив только те, что в 'train'\n",
        "\n",
        "        if not train_neighbors:\n",
        "            predictions[node_id] = random.randint(0, num_classes - 1)\n",
        "            continue\n",
        "\n",
        "        neighbor_labels = [node_info[n_id]['label'] for n_id in train_neighbors]\n",
        "\n",
        "        if not neighbor_labels:\n",
        "            # На случай, если соседи есть, но у них нет меток (хотя по логике выше это невозможно)\n",
        "            predictions[node_id] = random.randint(0, num_classes-1)\n",
        "            continue\n",
        "\n",
        "        label_counts = Counter(neighbor_labels)\n",
        "        predicted_class = ... # [!] ВАШ КОД: найдите самый частый класс\n",
        "        predictions[node_id] = predicted_class\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# --- Запуск бейзлайна ---\n",
        "baseline_predictions = graph_baseline_predictor(graph_data, embeddings_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4718b91-4ad3-4a4f-85cf-11c61fcbe36d",
      "metadata": {
        "id": "f4718b91-4ad3-4a4f-85cf-11c61fcbe36d"
      },
      "source": [
        "**Подсказка:** Если вы все сделаете правильно, точность этого бейзлайна должна быть в районе 0.4. По формуле оценки это даст вам около 2 баллов. Ваша цель — значительно превзойти этот результат!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "519111a6-43f7-4eff-b0b1-5698cfcd120b",
      "metadata": {
        "id": "519111a6-43f7-4eff-b0b1-5698cfcd120b"
      },
      "source": [
        "### Шаг 3: Функция для сохранения решения\n",
        "Определим функцию для выгрузки решения сразу. Она понадобится нам и для бейзлайна, и для финальной модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "707fcc33-5aeb-4883-8ca9-9438ca4d2459",
      "metadata": {
        "id": "707fcc33-5aeb-4883-8ca9-9438ca4d2459"
      },
      "outputs": [],
      "source": [
        "def save_predictions_to_csv(predictions_dict, filename=\"predictions.csv\"):\n",
        "    \"\"\"\n",
        "    Сохраняет предсказания из словаря в CSV файл для отправки в систему.\n",
        "    \"\"\"\n",
        "    # Убедимся, что predictions_dict содержит предсказания для всех тестовых вершин\n",
        "    test_ids = {d['id'] for d in embeddings_data if d['split'] == 'test'}\n",
        "    if set(predictions_dict.keys()) != test_ids:\n",
        "        print(\"Внимание! В словаре предсказаний отсутствуют некоторые тестовые ID.\")\n",
        "\n",
        "    pred_df = pd.DataFrame(list(predictions_dict.items()), columns=['id', 'label'])\n",
        "    pred_df = pred_df.sort_values(by='id')\n",
        "    pred_df.to_csv(filename, header=False, index=False)\n",
        "\n",
        "    print(f\"\\nРешение успешно сохранено в файл: {filename}\")\n",
        "    print(\"Пример содержимого файла:\")\n",
        "    # Магическая команда для вывода первых строк файла в Jupyter\n",
        "    !head -n 5 {filename}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3185d045-5cba-4a26-ba5d-e7c50684db32",
      "metadata": {
        "id": "3185d045-5cba-4a26-ba5d-e7c50684db32"
      },
      "outputs": [],
      "source": [
        "save_predictions_to_csv(baseline_predictions, \"baseline_predictions.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7925ed08-4922-4d46-88ae-e4a62626de54",
      "metadata": {
        "id": "7925ed08-4922-4d46-88ae-e4a62626de54"
      },
      "source": [
        "## Шаг 4: Построение финальной модели (GNN)\n",
        "Теперь ваша очередь построить графовую нейросеть! Вам предстоит пройти все этапы: подготовка данных, определение архитектуры, обучение и получение предсказаний."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "841f6395-967a-40be-8707-31968c86a3ae",
      "metadata": {
        "id": "841f6395-967a-40be-8707-31968c86a3ae"
      },
      "source": [
        "### 4.1: Подготовка данных и создание выборок\n",
        "Сначала подготовим данные в формате PyTorch Geometric. Самое важное — мы разделим обучающую выборку (train) на две части: новую, уменьшенную обучающую (new_train) и валидационную (val).\n",
        "\n",
        "Валидационная выборка критически важна для:\n",
        "\n",
        "- Настройки гиперпараметров (скорость обучения, глубина сети и т.д.).\n",
        "- Отслеживания переобучения и применения Early Stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b238fb40-2eec-4076-a38c-10c97cfd1250",
      "metadata": {
        "id": "b238fb40-2eec-4076-a38c-10c97cfd1250"
      },
      "outputs": [],
      "source": [
        "# --- Создание тензоров ---\n",
        "all_labels = {d['id']: d.get('label', -1) for d in embeddings_data}\n",
        "x = torch.tensor([d['embedding'] for d in embeddings_data], dtype=torch.float)\n",
        "y = torch.tensor([all_labels[i] for i in range(len(embeddings_data))], dtype=torch.long)\n",
        "edge_index = torch.tensor(graph_data, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# --- Создание масок ---\n",
        "# Сначала найдем ID всех обучающих вершин\n",
        "train_ids = [d['id'] for d in embeddings_data if d['split'] == 'train']\n",
        "\n",
        "# [!] ВАШ КОД: разделите `train_ids` на `train_ids_new` и `val_ids`\n",
        "# в соотношении 80/20. Используйте `train_test_split` из sklearn.\n",
        "# Не забудьте про `random_state` для воспроизводимости.\n",
        "train_ids_new, val_ids = ...\n",
        "\n",
        "# Теперь создаем маски PyTorch на основе этих ID\n",
        "train_mask = torch.zeros(len(embeddings_data), dtype=torch.bool)\n",
        "val_mask = torch.zeros(len(embeddings_data), dtype=torch.bool)\n",
        "test_mask = torch.zeros(len(embeddings_data), dtype=torch.bool)\n",
        "\n",
        "train_mask[train_ids_new] = True\n",
        "val_mask[val_ids] = True\n",
        "test_mask[[d['id'] for d in embeddings_data if d['split'] == 'test']] = True\n",
        "\n",
        "# Собираем все в один объект Data\n",
        "pyg_data = Data(x=x, edge_index=edge_index, y=y,\n",
        "                train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n",
        "\n",
        "print(\"Объект данных PyTorch Geometric:\")\n",
        "print(pyg_data)\n",
        "print(f\"Новый размер train: {pyg_data.train_mask.sum().item()}\")\n",
        "print(f\"Размер validation: {pyg_data.val_mask.sum().item()}\")\n",
        "print(f\"Размер test: {pyg_data.test_mask.sum().item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2882017-4a4d-402f-b254-f93b965210fc",
      "metadata": {
        "id": "c2882017-4a4d-402f-b254-f93b965210fc"
      },
      "source": [
        "### 4.2: Определение архитектуры модели\n",
        "Ваша задача — спроектировать и написать класс для GNN модели.\n",
        "\n",
        "Примерный план архитектуры:\n",
        "\n",
        "1. Вход: Принимает объект pyg_data.\n",
        "2. Слой 1: Графовый сверточный слой (например, GCNConv или GATConv), который преобразует входные эмбеддинги в промежуточное представление. После него — функция активации (например, ReLU).\n",
        "3. Регуляризация: Слой Dropout для борьбы с переобучением.\n",
        "4. Слой 2: Еще один графовый сверточный слой.\n",
        "5. Классификатор (MLP): После графовых слоев можно добавить небольшой полносвязный слой (nn.Linear) для финальной классификации.\n",
        "6. Выход: Логиты для каждого из 20 классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cdeeca2-c612-4159-ba70-00f7d19438ae",
      "metadata": {
        "id": "9cdeeca2-c612-4159-ba70-00f7d19438ae"
      },
      "outputs": [],
      "source": [
        "class MyGNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        # [!] ВАШ КОД: определите слои вашей модели здесь\n",
        "        # self.conv1 = ...\n",
        "        # self.dropout = ...\n",
        "        # self.conv2 = ...\n",
        "        # self.classifier_lin = ...\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        # [!] ВАШ КОД: опишите прямой проход данных через слои\n",
        "        # Не забудьте про функции активации и dropout\n",
        "\n",
        "        # x = self.conv1(...)\n",
        "        # x = F.relu(x)\n",
        "        # x = self.dropout(x)\n",
        "        # ...\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee4b1140-e4fb-4738-a963-6bc7e79e2037",
      "metadata": {
        "id": "ee4b1140-e4fb-4738-a963-6bc7e79e2037"
      },
      "source": [
        "### 4.3: Обучение модели\n",
        "Напишите цикл обучения. Следите за loss и accuracy на обучающей и валидационной выборках."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81bbdc4b-f0b9-4b77-b395-ec716e630fa9",
      "metadata": {
        "id": "81bbdc4b-f0b9-4b77-b395-ec716e630fa9"
      },
      "outputs": [],
      "source": [
        "# --- Настройка ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# [!] ВАШ КОД: создайте экземпляр вашей модели, оптимизатор и функцию потерь\n",
        "# model = MyGNN(...)\n",
        "# optimizer = ...\n",
        "# criterion = ...\n",
        "\n",
        "pyg_data = pyg_data.to(device)\n",
        "\n",
        "# --- Цикл обучения ---\n",
        "for epoch in range(1, 301): # Можете менять число эпох\n",
        "    # [!] ВАШ КОД: Напишите шаг обучения\n",
        "    # 1. Переключите модель в режим обучения: model.train()\n",
        "    # 2. Обнулите градиенты: optimizer.zero_grad()\n",
        "    # 3. Сделайте предсказание: out = model(pyg_data)\n",
        "    # 4. Посчитайте loss ТОЛЬКО на обучающей маске: loss = criterion(out[...], pyg_data.y[...])\n",
        "    # 5. Сделайте шаг назад: loss.backward()\n",
        "    # 6. Обновите веса: optimizer.step()\n",
        "\n",
        "    # --- Валидация ---\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            out = model(pyg_data)\n",
        "            pred = out.argmax(dim=1)\n",
        "\n",
        "            # [!] ВАШ КОД: посчитайте точность на train и val выборках\n",
        "            # train_acc = ...\n",
        "            # val_acc = ...\n",
        "\n",
        "            print(f'Эпоха: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7c7822-e625-43c4-9f19-b51f50edfe32",
      "metadata": {
        "id": "fc7c7822-e625-43c4-9f19-b51f50edfe32"
      },
      "source": [
        "## Шаг 5: Выгрузка решения\n",
        "После того, как вы обучили вашу лучшую модель и получили словарь final_predictions, его нужно сохранить в predictions.csv в правильном формате для отправки в систему."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ddb6bd4-4842-4e9b-b2fe-f02ee49dbe93",
      "metadata": {
        "id": "0ddb6bd4-4842-4e9b-b2fe-f02ee49dbe93"
      },
      "outputs": [],
      "source": [
        "# [!] ВАШ КОД:\n",
        "# 1. Переключите модель в режим оценки: model.eval()\n",
        "# 2. Сделайте предсказания для всех данных\n",
        "# 3. Выберите предсказания только для тестовой маски\n",
        "# 4. Преобразуйте их в словарь {id: label} и сохраните в `final_predictions`\n",
        "\n",
        "final_predictions = {} # Заполните этот словарь\n",
        "\n",
        "# Сохраняем финальное предсказание\n",
        "save_predictions_to_csv(final_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04824c82-424c-41f3-9784-0517751436a3",
      "metadata": {
        "id": "04824c82-424c-41f3-9784-0517751436a3"
      },
      "source": [
        "Готово! Теперь у вас есть файл predictions.csv, который можно загружать в систему. Попробуйте улучшить свой результат!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}